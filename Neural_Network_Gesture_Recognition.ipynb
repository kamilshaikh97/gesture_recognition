{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from imageio import imread\n",
    "import os\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "tf.random.set_seed(30)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install Pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('Project_data/val.csv').readlines())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'Project_data/train'\n",
    "val_path = 'Project_data/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image1 = PIL.Image.open(train_path+'/WIN_20180907_15_43_40_Pro_Stop Gesture_new/WIN_20180907_15_43_40_Pro_00011.png')\n",
    "w,h = image1.size\n",
    "print(w,h)\n",
    "image1=imread(train_path+'/WIN_20180907_15_43_40_Pro_Stop Gesture_new/WIN_20180907_15_43_40_Pro_00011.png')\n",
    "plt.imshow(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verifying cropping output on sample images\n",
    "image1=imread(train_path+'/WIN_20180907_15_43_40_Pro_Stop Gesture_new/WIN_20180907_15_43_40_Pro_00011.png')\n",
    "image1 = image1[20:,:-20]\n",
    "plt.imshow(image1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoGenerator:\n",
    "\n",
    "   # Function for defining image size\n",
    "    def imageparam(self,image_height,image_width):\n",
    "        self.image_height=image_height\n",
    "        self.image_width=image_width\n",
    "\n",
    "    # Function to define few other parameters\n",
    "    def othergenparam(self,num_epoches,batch_size,num_images):\n",
    "        self.num_epoches=num_epoches\n",
    "        self.batch_size=batch_size\n",
    "        self.num_images=num_images\n",
    "\n",
    "    # Generator Function\n",
    "    def generator(self,source_path,folder_list):\n",
    "        print( 'Source path = ', source_path, '; batch size =', self.batch_size)\n",
    "        img_idx = (np.linspace(0,29,self.num_images)).astype(int)\n",
    "        #create a list of image numbers you want to use for a particular video\n",
    "        while True:\n",
    "            t = np.random.permutation(folder_list)\n",
    "            num_batches = len(folder_list)//self.batch_size # calculate the number of batches\n",
    "            x=len(img_idx)\n",
    "            y=self.image_width\n",
    "            z=self.image_height\n",
    "            for batch in range(num_batches): # we iterate over the number of batches\n",
    "                batch_data = np.zeros((self.batch_size,x,y,z,3)) \n",
    "                #x is the number of images you use for each video,\n",
    "                # (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "                batch_labels = np.zeros((self.batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "                for folder in range(self.batch_size): # iterate over the batch_size\n",
    "                    imgs = os.listdir(source_path+'/'+ t[folder + (batch*self.batch_size)].split(';')[0]) \n",
    "            \n",
    "                    # read all the images in the folder\n",
    "                    for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                        image = imread(source_path+'/'+ t[folder + (batch*self.batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "        \n",
    "                        #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                        #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                        \n",
    "                        #cropping the image\n",
    "                        #selecting [20:,:-20] matrix as it seemed to be most suitable for maximum images\n",
    "                    \n",
    "                        #resizing the image\n",
    "                        image = image[20:,:-20]\n",
    "                        image = resize(image,(y,z,3))\n",
    "                        \n",
    "                        #batch_data[folder,idx,:,:,0] = image[:,:,0]-(image.mean()) #normalise and feed in the image\n",
    "                        batch_data[folder,idx,:,:,0] = image[:,:,0]/255 #normalise and feed in the image\n",
    "                        batch_data[folder,idx,:,:,1] = image[:,:,1]/255 #normalise and feed in the image\n",
    "                        batch_data[folder,idx,:,:,2] = image[:,:,2]/255 #normalise and feed in the image\n",
    "                        \n",
    "                    batch_labels[folder, int(t[folder + (batch*self.batch_size)].strip().split(';')[2])] = 1\n",
    "                yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "            \n",
    "            # write the code for the remaining data points which are left after full batches\n",
    "            rem_data = len(folder_list)%self.batch_size\n",
    "            if (rem_data != 0) :\n",
    "                batch_size = rem_data\n",
    "                num_batches = 1\n",
    "                for batch in range(num_batches): # we iterate over the number of batches\n",
    "                    batch_data = np.zeros((batch_size,x,y,z,3)) \n",
    "                    #x is the number of images you use for each video,\n",
    "                    # (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "                    batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "                    for folder in range(batch_size): # iterate over the batch_size\n",
    "                        imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) \n",
    "                    \n",
    "                        # read all the images in the folder\n",
    "                        for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                            image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                            \n",
    "                            #crop the images and resize them. Note that the images are of 2 different shape \n",
    "                            #and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "\n",
    "                            #cropping the image\n",
    "                            #selecting [20:,:-20] matrix as it seemed to be most suitable for maximum images\n",
    "                            #resizing the image\n",
    "                            \n",
    "                            image = image[20:,:-20]\n",
    "                            image = resize(image,(y,z,3))\n",
    "                            \n",
    "                            batch_data[folder,idx,:,:,0] = image[:,:,0]/255 #normalise and feed in the image\n",
    "                            batch_data[folder,idx,:,:,1] = image[:,:,1]/255 #normalise and feed in the image\n",
    "                            batch_data[folder,idx,:,:,2] = image[:,:,2]/255 #normalise and feed in the image\n",
    "\n",
    "                        batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "                    yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "    #Function to define parameters for model training           \n",
    "    def train_model(self,model):\n",
    "\n",
    "        curr_dt_time = datetime.datetime.now()\n",
    "\n",
    "        num_train_sequences = len(train_doc)\n",
    "        print('# training sequences =', num_train_sequences)\n",
    "        num_val_sequences = len(val_doc)\n",
    "        print('# validation sequences =', num_val_sequences)\n",
    "        num_epoches = self.num_epoches # choose the number of epochs\n",
    "        print ('# epoches =', num_epoches)\n",
    "\n",
    "        model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "        if not os.path.exists(model_name):\n",
    "            os.mkdir(model_name)\n",
    "                \n",
    "        filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "        \n",
    "        checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "        LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, verbose=1,min_lr=0.00001) # write the REducelronplateau code here\n",
    "        #using high factor value here as the validation accuracy is very low compared to train accuracy\n",
    "        \n",
    "        callbacks_list = [checkpoint, LR]\n",
    "        \n",
    "        #steps per epoch for train data\n",
    "        if (num_train_sequences%self.batch_size) == 0:\n",
    "            steps_per_epoch = int(num_train_sequences/self.batch_size)\n",
    "        else:\n",
    "            steps_per_epoch = (num_train_sequences//self.batch_size) + 1\n",
    "\n",
    "        #steps per epoch for val data\n",
    "        if (num_val_sequences%self.batch_size) == 0:\n",
    "            validation_steps = int(num_val_sequences/self.batch_size)\n",
    "        else:\n",
    "            validation_steps = (num_val_sequences//self.batch_size) + 1\n",
    "\n",
    "        train_generator = self.generator(train_path,train_doc)\n",
    "        val_generator = self.generator(val_path,val_doc)\n",
    "\n",
    "        # Model Fit \n",
    "        history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epoches, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)\n",
    "       \n",
    "        return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation,LSTM,Dropout,SimpleRNN\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from skimage.transform import resize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelbuild3D1(VideoGenerator):\n",
    "    def model_definition(self,filter=(3,3,3),dense_neurons=64,dropout=0.25):\n",
    "        input_shape_model = (self.num_images,self.image_width,self.image_height,3)\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filter, padding='same',input_shape=input_shape_model))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "        optimiser = 'adam'\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keeping the Batch size = 100 \n",
    "#keeping the Batch size huge the kernel dies automatically "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_3D1=modelbuild3D1()\n",
    "conv_3D1.imageparam(image_height=160,image_width=160)\n",
    "conv_3D1.othergenparam(num_epoches=5,batch_size=100,num_images=15)\n",
    "conv_3D1_model=conv_3D1.model_definition()\n",
    "conv_3D1_model.summary()\n",
    "print(\"Total Params:\", conv_3D1_model.count_params())\n",
    "model1 = conv_3D1.train_model(conv_3D1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3D2=modelbuild3D1()\n",
    "conv_3D2.imageparam(image_height=160,image_width=160)\n",
    "conv_3D2.othergenparam(num_epoches=5,batch_size=40,num_images=15)\n",
    "conv_3D2_model=conv_3D2.model_definition()\n",
    "conv_3D2_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Params:\", conv_3D2_model.count_params())\n",
    "model2 = conv_3D2.train_model(conv_3D2_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot(history):\n",
    "    fig, axes = plt.subplots(1,2, figsize=(15,4))\n",
    "\n",
    "    axes[0].plot(history.history['categorical_accuracy'],label='Training Accuracy')   \n",
    "    axes[0].plot(history.history['val_categorical_accuracy'],label='Validation Accuracy')\n",
    "    axes[0].legend(loc='lower right')\n",
    "    axes[0].title.set_text('Training and Validation Accuracy')\n",
    "\n",
    "    axes[1].plot(history.history['loss'],label='Training Loss')   \n",
    "    axes[1].plot(history.history['val_loss'],label='Validation Loss')\n",
    "    axes[1].legend(loc='upper right')\n",
    "    axes[1].title.set_text('Training and Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing number of images\n",
    "conv_3D3=modelbuild3D1()\n",
    "conv_3D3.imageparam(image_height=160,image_width=160)\n",
    "conv_3D3.othergenparam(num_epoches=5,batch_size=40,num_images=20)\n",
    "conv_3D3_model=conv_3D3.model_definition()\n",
    "conv_3D3_model.summary()\n",
    "print(\"Total Params:\", conv_3D3_model.count_params())\n",
    "model3 = conv_3D3.train_model(conv_3D3_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking impact of changing image dimensions only\n",
    "conv_3D4_1=modelbuild3D1()\n",
    "conv_3D4_1.imageparam(image_height=120,image_width=120)\n",
    "conv_3D4_1.othergenparam(num_epoches=5,batch_size=40,num_images=15)\n",
    "conv_3D4_1_model=conv_3D4_1.model_definition()\n",
    "conv_3D4_1_model.summary()\n",
    "print(\"Total Params:\", conv_3D4_1_model.count_params())\n",
    "model4_1 = conv_3D4_1.train_model(conv_3D4_1_model)\n",
    "plot(model4_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing number of images to 20\n",
    "conv_3D4=modelbuild3D1()\n",
    "conv_3D4.imageparam(image_height=120,image_width=120)\n",
    "conv_3D4.othergenparam(num_epoches=5,batch_size=40,num_images=20)\n",
    "conv_3D4_model=conv_3D4.model_definition()\n",
    "conv_3D4_model.summary()\n",
    "print(\"Total Params:\", conv_3D4_model.count_params())\n",
    "model4 = conv_3D4.train_model(conv_3D4_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing batch size\n",
    "conv_3D4=modelbuild3D1()\n",
    "conv_3D4.imageparam(image_height=120,image_width=120)\n",
    "conv_3D4.othergenparam(num_epoches=5,batch_size=32,num_images=20)\n",
    "conv_3D4_model=conv_3D4.model_definition()\n",
    "conv_3D4_model.summary()\n",
    "print(\"Total Params:\", conv_3D4_model.count_params())\n",
    "model4 = conv_3D4.train_model(conv_3D4_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_images=15\n",
    "conv_3D4=modelbuild3D1()\n",
    "conv_3D4.imageparam(image_height=120,image_width=120)\n",
    "conv_3D4.othergenparam(num_epoches=5,batch_size=32,num_images=15)\n",
    "conv_3D4_model=conv_3D4.model_definition()\n",
    "conv_3D4_model.summary()\n",
    "print(\"Total Params:\", conv_3D4_model.count_params())\n",
    "model4 = conv_3D4.train_model(conv_3D4_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelbuild3D2(VideoGenerator):\n",
    "    def model_definition(self,filter=(3,3,3),dense_neurons=128,dropout=0.25):\n",
    "        input_shape_model = (self.num_images,self.image_width,self.image_height,3)\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filter, padding='same',input_shape=input_shape_model))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "        optimiser = 'adam'\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_images=20,batchsize=40\n",
    "conv_3D2_1=modelbuild3D2()\n",
    "conv_3D2_1.imageparam(image_height=120,image_width=120)\n",
    "conv_3D2_1.othergenparam(num_epoches=5,batch_size=40,num_images=20)\n",
    "conv_3D2_1_model=conv_3D2_1.model_definition()\n",
    "conv_3D2_1_model.summary()\n",
    "print(\"Total Params:\", conv_3D2_1_model.count_params())\n",
    "model2_1 = conv_3D2_1.train_model(conv_3D2_1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model2_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing image dimensions\n",
    "conv_3D2_2=modelbuild3D2()\n",
    "conv_3D2_2.imageparam(image_height=100,image_width=100)\n",
    "conv_3D2_2.othergenparam(num_epoches=5,batch_size=40,num_images=20)\n",
    "conv_3D2_2_model=conv_3D2_2.model_definition()\n",
    "conv_3D2_2_model.summary()\n",
    "print(\"Total Params:\", conv_3D2_2_model.count_params())\n",
    "model2_2 = conv_3D2_2.train_model(conv_3D2_2_model)\n",
    "plot(model2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding one more layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelbuild3D3(VideoGenerator):\n",
    "    def model_definition(self,filter=(3,3,3),dense_neurons=64,dropout=0.25):\n",
    "        input_shape_model = (self.num_images,self.image_width,self.image_height,3)\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filter, padding='same',input_shape=input_shape_model))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Conv3D(128, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "        optimiser = 'adam'\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing num_images dimensions\n",
    "conv_3D3_1=modelbuild3D3()\n",
    "conv_3D3_1.imageparam(image_height=160,image_width=160)\n",
    "conv_3D3_1.othergenparam(num_epoches=5,batch_size=40,num_images=20)\n",
    "conv_3D3_1_model=conv_3D3_1.model_definition()\n",
    "conv_3D3_1_model.summary()\n",
    "print(\"Total Params:\", conv_3D3_1_model.count_params())\n",
    "model3_1 = conv_3D3_1.train_model(conv_3D3_1_model)\n",
    "plot(model3_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing num_images dimensions\n",
    "conv_3D3_3=modelbuild3D3()\n",
    "conv_3D3_3.imageparam(image_height=120,image_width=120)\n",
    "conv_3D3_3.othergenparam(num_epoches=5,batch_size=30,num_images=20)\n",
    "conv_3D3_3_model=conv_3D3_3.model_definition()\n",
    "conv_3D3_3_model.summary()\n",
    "print(\"Total Params:\", conv_3D3_3_model.count_params())\n",
    "model3_3 = conv_3D3_3.train_model(conv_3D3_3_model)\n",
    "plot(model3_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelbuild3D4(VideoGenerator):\n",
    "    def model_definition(self,filter=(3,3,3),dense_neurons=64,dropout=0.25):\n",
    "        input_shape_model = (self.num_images,self.image_width,self.image_height,3)\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filter, padding='same',input_shape=input_shape_model))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Conv3D(128, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "        optimiser = 'adam'\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing num_images dimensions\n",
    "conv_3D4_1=modelbuild3D4()\n",
    "conv_3D4_1.imageparam(image_height=120,image_width=120)\n",
    "conv_3D4_1.othergenparam(num_epoches=5,batch_size=40,num_images=20)\n",
    "conv_3D4_1_model=conv_3D4_1.model_definition()\n",
    "conv_3D4_1_model.summary()\n",
    "print(\"Total Params:\", conv_3D4_1_model.count_params())\n",
    "model4_1 = conv_3D4_1.train_model(conv_3D4_1_model)\n",
    "plot(model4_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing num_images dimensions\n",
    "conv_3D4_3=modelbuild3D4()\n",
    "conv_3D4_3.imageparam(image_height=120,image_width=120)\n",
    "conv_3D4_3.othergenparam(num_epoches=5,batch_size=25,num_images=20)\n",
    "conv_3D4_3_model=conv_3D4_3.model_definition()\n",
    "conv_3D4_3_model.summary()\n",
    "print(\"Total Params:\", conv_3D4_3_model.count_params())\n",
    "model4_3 = conv_3D4_3.train_model(conv_3D4_3_model)\n",
    "plot(model4_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing Dropout\n",
    "class modelbuild3D5(VideoGenerator):\n",
    "    def model_definition(self,filter=(3,3,3),dense_neurons=64,dropout=0.5):\n",
    "        input_shape_model = (self.num_images,self.image_width,self.image_height,3)\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filter, padding='same',input_shape=input_shape_model))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Conv3D(128, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "        optimiser = 'adam'\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing num_images dimensions\n",
    "conv_3D5_1=modelbuild3D5()\n",
    "conv_3D5_1.imageparam(image_height=120,image_width=120)\n",
    "conv_3D5_1.othergenparam(num_epoches=5,batch_size=30,num_images=20)\n",
    "conv_3D5_1_model=conv_3D5_1.model_definition()\n",
    "conv_3D5_1_model.summary()\n",
    "print(\"Total Params:\", conv_3D5_1_model.count_params())\n",
    "model5_1 = conv_3D5_1.train_model(conv_3D5_1_model)\n",
    "plot(model5_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing Dropout\n",
    "class modelbuild3D6(VideoGenerator):\n",
    "    def model_definition(self,filter=(3,3,3),dense_neurons=64,dropout=0.2):\n",
    "        input_shape_model = (self.num_images,self.image_width,self.image_height,3)\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filter, padding='same',input_shape=input_shape_model))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Conv3D(128, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "        optimiser = 'adam'\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3D6_1=modelbuild3D6()\n",
    "conv_3D6_1.imageparam(image_height=120,image_width=120)\n",
    "conv_3D6_1.othergenparam(num_epoches=5,batch_size=30,num_images=20)\n",
    "conv_3D6_1_model=conv_3D6_1.model_definition()\n",
    "conv_3D6_1_model.summary()\n",
    "print(\"Total Params:\", conv_3D6_1_model.count_params())\n",
    "model6_1 = conv_3D6_1.train_model(conv_3D6_1_model)\n",
    "plot(model6_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing number of neurons\n",
    "class modelbuild3D7(VideoGenerator):\n",
    "    def model_definition(self,filter=(3,3,3),dense_neurons=128,dropout=0.2):\n",
    "        input_shape_model = (self.num_images,self.image_width,self.image_height,3)\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filter, padding='same',input_shape=input_shape_model))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Conv3D(128, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "        optimiser = 'adam'\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3D7_1=modelbuild3D7()\n",
    "conv_3D7_1.imageparam(image_height=120,image_width=120)\n",
    "conv_3D7_1.othergenparam(num_epoches=5,batch_size=30,num_images=20)\n",
    "conv_3D7_1_model=conv_3D7_1.model_definition()\n",
    "conv_3D7_1_model.summary()\n",
    "print(\"Total Params:\", conv_3D7_1_model.count_params())\n",
    "model7_1 = conv_3D7_1.train_model(conv_3D7_1_model)\n",
    "plot(model7_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing filters to 2,2,2\n",
    "#Changing number of neurons\n",
    "class modelbuild3D8(VideoGenerator):\n",
    "    def model_definition(self,filter=(2,2,2),dense_neurons=64,dropout=0.2):\n",
    "        input_shape_model = (self.num_images,self.image_width,self.image_height,3)\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filter, padding='same',input_shape=input_shape_model))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Conv3D(128, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "        optimiser = 'adam'\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conv_3D8_1=modelbuild3D8()\n",
    "conv_3D8_1.imageparam(image_height=120,image_width=120)\n",
    "conv_3D8_1.othergenparam(num_epoches=5,batch_size=30,num_images=20)\n",
    "conv_3D8_1_model=conv_3D8_1.model_definition()\n",
    "conv_3D8_1_model.summary()\n",
    "print(\"Total Params:\", conv_3D8_1_model.count_params())\n",
    "model8_1 = conv_3D8_1.train_model(conv_3D8_1_model)\n",
    "plot(model8_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing Optimiser to sgd\n",
    "class modelbuild3D9(VideoGenerator):\n",
    "    def model_definition(self,filter=(2,2,2),dense_neurons=64,dropout=0.2):\n",
    "        input_shape_model = (self.num_images,self.image_width,self.image_height,3)\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filter, padding='same',input_shape=input_shape_model))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Conv3D(128, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "        optimiser = 'sgd'\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3D9_1=modelbuild3D9()\n",
    "conv_3D9_1.imageparam(image_height=120,image_width=120)\n",
    "conv_3D9_1.othergenparam(num_epoches=5,batch_size=40,num_images=20)\n",
    "conv_3D9_1_model=conv_3D9_1.model_definition()\n",
    "conv_3D9_1_model.summary()\n",
    "print(\"Total Params:\", conv_3D9_1_model.count_params())\n",
    "model9_1 = conv_3D9_1.train_model(conv_3D9_1_model)\n",
    "plot(model9_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing to 256 neurons \n",
    "class modelbuild3D10(VideoGenerator):\n",
    "    def model_definition(self,filter=(2,2,2),dense_neurons=256,dropout=0.2):\n",
    "        input_shape_model = (self.num_images,self.image_width,self.image_height,3)\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filter, padding='same',input_shape=input_shape_model))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Conv3D(128, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "        optimiser = 'adam'\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further Analysing Using a model having 128 neurons by decreasing the batch size further\n",
    "class modelbuild3D11(VideoGenerator):\n",
    "    def model_definition(self,filter=(3,3,3),dense_neurons=128,dropout=0.25):\n",
    "        input_shape_model = (self.num_images,self.image_width,self.image_height,3)\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filter, padding='same',input_shape=input_shape_model))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "        optimiser = 'adam'\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3D10_1=modelbuild3D10()\n",
    "conv_3D10_1.imageparam(image_height=120,image_width=120)\n",
    "conv_3D10_1.othergenparam(num_epoches=5,batch_size=40,num_images=20)\n",
    "conv_3D10_1_model=conv_3D10_1.model_definition()\n",
    "conv_3D10_1_model.summary()\n",
    "print(\"Total Params:\", conv_3D10_1_model.count_params())\n",
    "model10_1 = conv_3D10_1.train_model(conv_3D10_1_model)\n",
    "plot(model10_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3D11_1=modelbuild3D11()\n",
    "conv_3D11_1.imageparam(image_height=120,image_width=120)\n",
    "conv_3D11_1.othergenparam(num_epoches=5,batch_size=20,num_images=25)\n",
    "conv_3D11_1_model=conv_3D11_1.model_definition()\n",
    "conv_3D11_1_model.summary()\n",
    "print(\"Total Params:\", conv_3D11_1_model.count_params())\n",
    "model11_1 = conv_3D11_1.train_model(conv_3D11_1_model)\n",
    "plot(model11_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelbuild3D12(VideoGenerator):\n",
    "    def model_definition(self,filter=(3,3,3),dense_neurons=64,dropout=0.25):\n",
    "        input_shape_model = (self.num_images,self.image_width,self.image_height,3)\n",
    "        model = Sequential()\n",
    "        model.add(Conv3D(16, filter, padding='same',input_shape=input_shape_model))\n",
    "        model.add(Activation('relu'))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filter, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "        optimiser = 'adam'\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3D12_1=modelbuild3D12()\n",
    "conv_3D12_1.imageparam(image_height=120,image_width=120)\n",
    "conv_3D12_1.othergenparam(num_epoches=5,batch_size=20,num_images=20)\n",
    "conv_3D12_1_model=conv_3D12_1.model_definition(dense_neurons=128,dropout=0.2)\n",
    "conv_3D12_1_model.summary()\n",
    "print(\"Total Params:\", conv_3D12_1_model.count_params())\n",
    "model12_1 = conv_3D12_1.train_model(conv_3D12_1_model)\n",
    "plot(model12_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3D12_2=modelbuild3D12()\n",
    "conv_3D12_2.imageparam(image_height=140,image_width=140)\n",
    "conv_3D12_2.othergenparam(num_epoches=5,batch_size=20,num_images=20)\n",
    "conv_3D12_2_model=conv_3D12_2.model_definition(dense_neurons=128,dropout=0.2)\n",
    "conv_3D12_2_model.summary()\n",
    "print(\"Total Params:\", conv_3D12_2_model.count_params())\n",
    "model12_2 = conv_3D12_2.train_model(conv_3D12_2_model)\n",
    "plot(model12_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3D12_4=modelbuild3D12()\n",
    "conv_3D12_4.imageparam(image_height=120,image_width=120)\n",
    "conv_3D12_4.othergenparam(num_epoches=5,batch_size=20,num_images=25)\n",
    "conv_3D12_4_model=conv_3D12_4.model_definition(dense_neurons=128,dropout=0.2)\n",
    "conv_3D12_4_model.summary()\n",
    "print(\"Total Params:\", conv_3D12_4_model.count_params())\n",
    "model12_4 = conv_3D12_4.train_model(conv_3D12_4_model)\n",
    "plot(model12_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3D12_5=modelbuild3D12()\n",
    "conv_3D12_5.imageparam(image_height=120,image_width=120)\n",
    "conv_3D12_5.othergenparam(num_epoches=5,batch_size=15,num_images=25)\n",
    "conv_3D12_5_model=conv_3D12_5.model_definition(dense_neurons=128,dropout=0.2)\n",
    "conv_3D12_5_model.summary()\n",
    "print(\"Total Params:\", conv_3D12_5_model.count_params())\n",
    "model12_5 = conv_3D12_5.train_model(conv_3D12_5_model)\n",
    "plot(model12_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Padding\n",
    "class modelbuild3D13(VideoGenerator):\n",
    "    def model_definition(self,filter=(3,3,3),dense_neurons=128,dropout=0.5):\n",
    "        input_shape_model = (self.num_images,self.image_width,self.image_height,3)\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv3D(16, filter,input_shape=input_shape_model))\n",
    "        model.add(Activation('relu'))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filter))\n",
    "        model.add(Activation('relu'))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filter))\n",
    "        model.add(Activation('relu'))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "        optimiser = 'adam'\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3D13_1=modelbuild3D13()\n",
    "conv_3D13_1.imageparam(image_height=120,image_width=120)\n",
    "conv_3D13_1.othergenparam(num_epoches=15,batch_size=20,num_images=23)\n",
    "conv_3D13_1_model=conv_3D13_1.model_definition()\n",
    "conv_3D13_1_model.summary()\n",
    "print(\"Total Params:\", conv_3D13_1_model.count_params())\n",
    "model13_1 = conv_3D13_1.train_model(conv_3D13_1_model)\n",
    "plot(model13_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3D13_2=modelbuild3D13()\n",
    "conv_3D13_2.imageparam(image_height=120,image_width=120)\n",
    "conv_3D13_2.othergenparam(num_epoches=15,batch_size=20,num_images=23)\n",
    "conv_3D13_2_model=conv_3D13_2.model_definition(dropout=0.2)\n",
    "conv_3D13_2_model.summary()\n",
    "print(\"Total Params:\", conv_3D13_2_model.count_params())\n",
    "model13_2 = conv_3D13_2.train_model(conv_3D13_2_model)\n",
    "plot(model13_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3D13_3=modelbuild3D13()\n",
    "conv_3D13_3.imageparam(image_height=120,image_width=120)\n",
    "conv_3D13_3.othergenparam(num_epoches=15,batch_size=18,num_images=23)\n",
    "conv_3D13_3_model=conv_3D13_3.model_definition()\n",
    "conv_3D13_3_model.summary()\n",
    "print(\"Total Params:\", conv_3D13_3_model.count_params())\n",
    "model13_3 = conv_3D13_3.train_model(conv_3D13_3_model)\n",
    "plot(model13_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3D13_4=modelbuild3D13()\n",
    "conv_3D13_4.imageparam(image_height=120,image_width=120)\n",
    "conv_3D13_4.othergenparam(num_epoches=15,batch_size=20,num_images=22)\n",
    "conv_3D13_4_model=conv_3D13_4.model_definition()\n",
    "conv_3D13_4_model.summary()\n",
    "print(\"Total Params:\", conv_3D13_4_model.count_params())\n",
    "model13_4 = conv_3D13_4.train_model(conv_3D13_4_model)\n",
    "plot(model13_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3D13_5=modelbuild3D13()\n",
    "conv_3D13_5.imageparam(image_height=120,image_width=120)\n",
    "conv_3D13_5.othergenparam(num_epoches=15,batch_size=32,num_images=25)\n",
    "conv_3D13_5_model=conv_3D13_5.model_definition()\n",
    "conv_3D13_5_model.summary()\n",
    "print(\"Total Params:\", conv_3D13_5_model.count_params())\n",
    "model13_5 = conv_3D13_5.train_model(conv_3D13_5_model)\n",
    "plot(model13_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Padding\n",
    "class modelbuild3D14(VideoGenerator):\n",
    "    def model_definition(self,filter=(3,3,3),dense_neurons=128,dropout=0.5):\n",
    "        input_shape_model = (self.num_images,self.image_width,self.image_height,3)\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv3D(16, filter,input_shape=input_shape_model))\n",
    "        model.add(Activation('relu'))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(32, filter))\n",
    "        model.add(Activation('relu'))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "        model.add(Conv3D(64, filter))\n",
    "        model.add(Activation('relu'))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "        model.add(Dropout(dropout))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "        model.add(Dense(5,activation='softmax'))\n",
    "\n",
    "        optimiser = 'adam'\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_3D14_1=modelbuild3D14()\n",
    "conv_3D14_1.imageparam(image_height=120,image_width=120)\n",
    "conv_3D14_1.othergenparam(num_epoches=15,batch_size=20,num_images=23)\n",
    "conv_3D14_1_model=conv_3D14_1.model_definition(dropout=0.2)\n",
    "conv_3D14_1_model.summary()\n",
    "print(\"Total Params:\", conv_3D14_1_model.count_params())\n",
    "model14_1 = conv_3D14_1.train_model(conv_3D14_1_model)\n",
    "plot(model14_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3D RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2DRNN_1(VideoGenerator):\n",
    "\n",
    "    def model_definition(self,filter=(3,3),dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        input_shape_model = (self.num_images,self.image_width,self.image_height,3)\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(Conv2D(16, filter , padding='same', activation='relu'),input_shape=input_shape_model))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "                \n",
    "        model.add(TimeDistributed(Conv2D(32, filter , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "                \n",
    "        model.add(TimeDistributed(Conv2D(64, filter , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "                \n",
    "        model.add(TimeDistributed(Conv2D(128, filter , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "                \n",
    "        model.add(TimeDistributed(Conv2D(256, filter , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "\n",
    "        model.add(LSTM(dense_neurons))\n",
    "        model.add(Dropout(dropout))\n",
    "                \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "                \n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "        optimiser = 'adam'\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade numpy==1.19.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_2drnn_1=Model2DRNN_1()\n",
    "conv_2drnn_1.imageparam(image_height=120,image_width=120)\n",
    "conv_2drnn_1.othergenparam(num_epoches=5,batch_size=50,num_images=15)\n",
    "conv_2drnn_1_model=conv_2drnn_1.model_definition()\n",
    "conv_2drnn_1_model.summary()\n",
    "print(\"Total Params:\", conv_2drnn_1_model.count_params())\n",
    "model2d1_1 = conv_2drnn_1.train_model(conv_2drnn_1_model)\n",
    "plot(model2d1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_2drnn_2=Model2DRNN_1()\n",
    "conv_2drnn_2.imageparam(image_height=120,image_width=120)\n",
    "conv_2drnn_2.othergenparam(num_epoches=5,batch_size=20,num_images=15)\n",
    "conv_2drnn_2_model=conv_2drnn_2.model_definition()\n",
    "conv_2drnn_2_model.summary()\n",
    "print(\"Total Params:\", conv_2drnn_2_model.count_params())\n",
    "model2d1_2 = conv_2drnn_2.train_model(conv_2drnn_2_model)\n",
    "plot(model2d1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_2drnn_3=Model2DRNN_1()\n",
    "conv_2drnn_3.imageparam(image_height=120,image_width=120)\n",
    "conv_2drnn_3.othergenparam(num_epoches=5,batch_size=20,num_images=20)\n",
    "conv_2drnn_3_model=conv_2drnn_3.model_definition()\n",
    "conv_2drnn_3_model.summary()\n",
    "print(\"Total Params:\", conv_2drnn_3_model.count_params())\n",
    "model2d1_3 = conv_2drnn_3.train_model(conv_2drnn_3_model)\n",
    "plot(model2d1_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_2drnn_4=Model2DRNN_1()\n",
    "conv_2drnn_4.imageparam(image_height=120,image_width=120)\n",
    "conv_2drnn_4.othergenparam(num_epoches=5,batch_size=20,num_images=20)\n",
    "conv_2drnn_4_model=conv_2drnn_4.model_definition(dropout=0.5)\n",
    "conv_2drnn_4_model.summary()\n",
    "print(\"Total Params:\", conv_2drnn_4_model.count_params())\n",
    "model2d1_4 = conv_2drnn_4.train_model(conv_2drnn_4_model)\n",
    "plot(model2d1_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRU\n",
    "class Model2DRNN_2(VideoGenerator):\n",
    "\n",
    "    def model_definition(self,filter=(3,3),dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        input_shape_model = (self.num_images,self.image_width,self.image_height,3)\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(Conv2D(16, filter , padding='same', activation='relu'),input_shape=input_shape_model))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "                \n",
    "        model.add(TimeDistributed(Conv2D(32, filter , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "                \n",
    "        model.add(TimeDistributed(Conv2D(64, filter , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "                \n",
    "        model.add(TimeDistributed(Conv2D(128, filter , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "                \n",
    "        model.add(TimeDistributed(Conv2D(256, filter , padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "        model.add(GRU(dense_neurons))\n",
    "        model.add(Dropout(dropout))\n",
    "                \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "                \n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "        optimiser = 'adam'\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_2drnn_2_1=Model2DRNN_2()\n",
    "conv_2drnn_2_1.imageparam(image_height=120,image_width=120)\n",
    "conv_2drnn_2_1.othergenparam(num_epoches=5,batch_size=20,num_images=20)\n",
    "conv_2drnn_2_1_model=conv_2drnn_2_1.model_definition()\n",
    "conv_2drnn_2_1_model.summary()\n",
    "print(\"Total Params:\", conv_2drnn_2_1_model.count_params())\n",
    "model2d2_1 = conv_2drnn_2_1.train_model(conv_2drnn_2_1_model)\n",
    "plot(model2d2_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_2drnn_2_2=Model2DRNN_2()\n",
    "conv_2drnn_2_2.imageparam(image_height=120,image_width=120)\n",
    "conv_2drnn_2_2.othergenparam(num_epoches=5,batch_size=20,num_images=24)\n",
    "conv_2drnn_2_2_model=conv_2drnn_2_2.model_definition()\n",
    "conv_2drnn_2_2_model.summary()\n",
    "print(\"Total Params:\", conv_2drnn_2_2_model.count_params())\n",
    "model2d2_2 = conv_2drnn_2_2.train_model(conv_2drnn_2_2_model)\n",
    "plot(model2d2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRU and removing BN\n",
    "class Model2DRNN_4(VideoGenerator):\n",
    "\n",
    "    def model_definition(self,filter=(3,3),dense_neurons=64,dropout=0.25):\n",
    "\n",
    "        input_shape_model = (self.num_images,self.image_width,self.image_height,3)\n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(Conv2D(16, filter , padding='same', activation='relu'),input_shape=input_shape_model))\n",
    "       # model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "                \n",
    "        model.add(TimeDistributed(Conv2D(32, filter , padding='same', activation='relu')))\n",
    "       # model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "                \n",
    "        model.add(TimeDistributed(Conv2D(64, filter , padding='same', activation='relu')))\n",
    "       # model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "                \n",
    "        model.add(TimeDistributed(Conv2D(128, filter , padding='same', activation='relu')))\n",
    "        #model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "                \n",
    "        model.add(TimeDistributed(Conv2D(256, filter , padding='same', activation='relu')))\n",
    "        #model.add(TimeDistributed(BatchNormalization()))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "        model.add(GRU(dense_neurons))\n",
    "        model.add(Dropout(dropout))\n",
    "                \n",
    "        model.add(Dense(dense_neurons,activation='relu'))\n",
    "        model.add(Dropout(dropout))\n",
    "                \n",
    "        model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "        optimiser = 'adam'\n",
    "        model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_2drnn_4_1=Model2DRNN_4()\n",
    "conv_2drnn_4_1.imageparam(image_height=120,image_width=120)\n",
    "conv_2drnn_4_1.othergenparam(num_epoches=5,batch_size=20,num_images=20)\n",
    "conv_2drnn_4_1_model=conv_2drnn_4_1.model_definition()\n",
    "conv_2drnn_4_1_model.summary()\n",
    "print(\"Total Params:\", conv_2drnn_4_1_model.count_params())\n",
    "model2d4_1 = conv_2drnn_4_1.train_model(conv_2drnn_4_1_model)\n",
    "plot(model2d4_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_2drnn_4_2=Model2DRNN_4()\n",
    "conv_2drnn_4_2.imageparam(image_height=120,image_width=120)\n",
    "conv_2drnn_4_2.othergenparam(num_epoches=15,batch_size=20,num_images=18)\n",
    "conv_2drnn_4_2_model=conv_2drnn_4_2.model_definition()\n",
    "conv_2drnn_4_2_model.summary()\n",
    "print(\"Total Params:\", conv_2drnn_4_2_model.count_params())\n",
    "model2d4_2 = conv_2drnn_4_2.train_model(conv_2drnn_4_2_model)\n",
    "plot(model2d4_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
